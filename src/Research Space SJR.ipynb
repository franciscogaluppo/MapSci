{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The  Research  Space\n",
    "\n",
    "\"Here we use a large dataset of scholarly publications disambiguated at the individual level to create a map of science — or research  space — where links connect pairs of fields based on the probability that an individual has published in both of them.\"\n",
    "[Original Article](https://arxiv.org/ftp/arxiv/papers/1602/1602.08409.pdf)\n",
    "\n",
    "[Artigo suplementar](https://link.springer.com/content/pdf/10.1140/epjds/s13688-019-0210-z.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data\n",
    "\n",
    "PRECISO CHECAR O PARSER NOVAMENTE. ALGUNS ANOS APARECERAM COMO 'rint' OU 'onic'. E EM ALGUNS ARTIGOS O NÚMERO DE AUTORES FOI ZERO.\n",
    "\n",
    "Todas as publicações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(\"../dataset/lattes_categories.csv\", sep=\";sep;\", engine=\"python\")\n",
    "articles = articles[(articles[\"ano\"] != 'rint') & (articles[\"ano\"] != 'onic')]\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados das categorias:\n",
    "\n",
    "O dicionário abaixo é a classificação intermediária de acordo com o Scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clss = dict()\n",
    "clss[10] = \"multidisciplinary\"\n",
    "clss[11] = \"agricultural and biological sciences\"\n",
    "clss[12] = \"arts and humanities\"\n",
    "clss[13] = \"biochemistry, genetics and molecular biology\"\n",
    "clss[14] = \"business, management and accounting\"\n",
    "clss[15] = \"chemical engineering\"\n",
    "clss[16] = \"chemistry\"\n",
    "clss[17] = \"computer science\"\n",
    "clss[18] = \"decision sciences\"\n",
    "clss[19] = \"earth and planetary sciences\"\n",
    "clss[20] = \"economics, econometrics and finance\"\n",
    "clss[21] = \"energy\"\n",
    "clss[22] = \"engineering\"\n",
    "clss[23] = \"environmental science\"\n",
    "clss[24] = \"immunology and microbiology\"\n",
    "clss[25] = \"materials science\"\n",
    "clss[26] = \"mathematics\"\n",
    "clss[27] = \"medicine\"\n",
    "clss[28] = \"neuroscience\"\n",
    "clss[29] = \"nursing\"\n",
    "clss[30] = \"pharmacology, toxicology and pharmaceutics\"\n",
    "clss[31] = \"physics and astronomy\"\n",
    "clss[32] = \"psychology\"\n",
    "clss[33] = \"social sciences\"\n",
    "clss[34] = \"veterinary\"\n",
    "clss[35] = \"dentistry\"\n",
    "clss[36] = \"health professions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ler e adicionar uma nova coluna de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = pd.read_csv(\"../dataset/SJR/areas.txt\", sep=\";\")\n",
    "areas[\"Field\"] = areas[\"Field\"].apply(lambda x: x.strip().lower())\n",
    "areas[\"Subject area\"] = areas[\"Subject area\"].apply(lambda x: x.strip().lower())\n",
    "areas[\"Classification\"] = areas[\"Code\"].apply(lambda x: clss[int(str(x)[:2])])\n",
    "areas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, temos que adicionar algumas áreas que não foram cadastradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = areas.append({'Field': 'e-learning', 'Subject area': \"social sciences & humanities\",\n",
    "                      \"Classification\": \"social sciences\"} , ignore_index=True)\n",
    "areas = areas.append({'Field': 'nanoscience and nanotechnology', 'Subject area': \"physical sciences\",\n",
    "                      \"Classification\": \"materials science\"} , ignore_index=True)\n",
    "areas = areas.append({'Field': 'social work', 'Subject area': \"social sciences & humanities\",\n",
    "                      \"Classification\": \"social sciences\"} , ignore_index=True)\n",
    "areas = areas.append({'Field': 'sports science', 'Subject area': \"health sciences\",\n",
    "                      \"Classification\": \"health professions\"} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instituição do pesquisador, caso queiramos agregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio = pd.read_csv(\"../dataset/lattes/pesquisadores.csv\", sep=\";sep;\", engine=\"python\")\n",
    "bio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "\"We filter this dataset by focusing only on scholars with less than fifty publications in each year, because those with more than fifty publications tend to have many publications that are miss-assigned and are not theirs\"\n",
    "\n",
    "VOU IGNORAR PORQUE NO LATTES É O USUÁRIO QUEM COLOCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Space\n",
    "\n",
    "\" $\\phi_{ff'}(T)$ is  the  adjacency  matrix  representing  the  research  space expressed  by  the  career trajectory of scientists in our dataset observed up to time T. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the categories from an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catg(s):\n",
    "    return [re.sub(r\"\\s?\\(Q[1-9]\\)\", \"\", x).strip().lower() for x in s.split(\";\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dict to represent the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X(t):\n",
    "    x = dict()\n",
    "    for _, row in articles.iterrows():\n",
    "        if int(row[\"ano\"]) < t:\n",
    "            fs = catg(row[\"catg\"])\n",
    "            nf = len(fs)\n",
    "            for field in fs:\n",
    "                \n",
    "                if row[\"num\"] == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (row[\"pesq\"], field) in x:\n",
    "                    x[(row[\"pesq\"], field)] += 1/(nf * row[\"num\"])\n",
    "                else:\n",
    "                    x[(row[\"pesq\"], field)] = 1/(nf * row[\"num\"])\n",
    "    \n",
    "    print(\"X done\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dict to represent the P matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(t):\n",
    "    x = X(t)\n",
    "    p = dict()\n",
    "    \n",
    "    for sf in x:\n",
    "        if x[sf] > 0.1:\n",
    "            p[sf] = 1\n",
    "            \n",
    "    print(\"P done\")\n",
    "    return [p, x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the M matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M(t):\n",
    "    p, x = P(t)\n",
    "    s = set()\n",
    "    f = set()\n",
    "    \n",
    "    for sf in p:\n",
    "        s.add(sf[0])\n",
    "        f.add(sf[1])\n",
    "        \n",
    "    of = sorted(list(f))\n",
    "    indices = {u: v for v, u in enumerate(of)}\n",
    "    n = len(of)\n",
    "    m = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(len(of)):\n",
    "        for j in range(i+1, len(of)):\n",
    "            for k in s:\n",
    "                if (k,of[i]) in p and (k,of[j]) in p:\n",
    "                    m[i,j] += 1\n",
    "                    m[j,i] += 1\n",
    "                    \n",
    "    print(\"M done\")\n",
    "    return [m, p, of, x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the phi matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(t):\n",
    "    m, p, of, x = M(t)\n",
    "    indices = dict()\n",
    "    sums = np.zeros(len(m))\n",
    "    \n",
    "    for sf in p:\n",
    "        if sf[1] not in indices:\n",
    "            indices[sf[1]] = of.index(sf[1])\n",
    "        sums[indices[sf[1]]] += 1\n",
    "\n",
    "    phi = m.copy()\n",
    "    for i in range(len(m)):\n",
    "        phi[:,i] /= sums[i]\n",
    "    \n",
    "    print(\"phi done\")\n",
    "    return [phi, of, x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar só pra ter certeza né. As etapas do X e do M são bastante demoradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, of, x = phi(2011)\n",
    "np.save(\"../dataset/phi_matrix_2011.npy\", k)\n",
    "np.save(\"../dataset/x_dict_2011.npy\", x)\n",
    "\n",
    "with open(\"../dataset/of_2011.txt\", \"w\") as f:\n",
    "    for item in of:\n",
    "        f.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.load(\"../dataset/phi_matrix_2011.npy\")\n",
    "x = np.load(\"../dataset/x_dict_2011.npy\", allow_pickle='TRUE').item()\n",
    "\n",
    "of = list()\n",
    "with open(\"../dataset/of_2011.txt\", \"r\") as f:\n",
    "    for item in f:\n",
    "        of.append(item.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(k, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(area, subs):\n",
    "    values = [subs[area[node]] for node in of]\n",
    "\n",
    "    cm = plt.get_cmap('gist_ncar')\n",
    "    cNorm = colors.Normalize(vmin=0, vmax=max(values))\n",
    "    scalar_map = cmx.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "    \n",
    "    return [cm, scalar_map, values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get node size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_size():\n",
    "    values = [40 for node in of]\n",
    "    values[of.index(\"computer science applications\")] = 300    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph(A, area, subs, pos=None, threshold=0.212):\n",
    "    G = nx.from_numpy_matrix(A)\n",
    "    mast = nx.maximum_spanning_tree(G)\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(A)):\n",
    "            if i != j:\n",
    "                if A[i,j] > threshold:\n",
    "                    mast.add_edge(i,j)\n",
    "        \n",
    "    if pos == None:\n",
    "        pos = nx.spring_layout(mast)\n",
    "    \n",
    "    cm, scalarMap, values = get_colors(area, subs)\n",
    "    \n",
    "    f = plt.figure(1)\n",
    "    ax = f.add_subplot(1,1,1)\n",
    "    for label in subs:\n",
    "        ax.plot([0],[0], color = scalarMap.to_rgba(subs[label]), label = label, lw=7)\n",
    "        \n",
    "    nx.draw_networkx(mast, pos, cmap=cm, vmin=0, vmax= max(values), node_color=values, with_labels=False,\n",
    "                     ax=ax, node_size=get_node_size(), edge_size=1, edge_color=\"lightgray\")\n",
    "                                                                                                            \n",
    "    plt.axis('off')\n",
    "    f.set_facecolor('w')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using macro subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_area = areas[[\"Field\", \"Subject area\"]].set_index(\"Field\").to_dict()[\"Subject area\"]\n",
    "unique = areas[\"Subject area\"].unique()\n",
    "subs = {u: v for v,u in enumerate(sorted(unique))}\n",
    "\n",
    "pos = show_graph(k, dict_area, subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos variar o valor do threshold para melhor visualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(th):\n",
    "    show_graph(k, dict_area, subs, pos, th)\n",
    "\n",
    "interact(f, th=(0.05,0.95,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using intermediate classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_area = areas[[\"Field\", \"Classification\"]].set_index(\"Field\").to_dict()[\"Classification\"]\n",
    "unique = areas[\"Classification\"].unique()\n",
    "subs = {u: v for v,u in enumerate(sorted(unique))}\n",
    "\n",
    "pos = show_graph(k, dict_area, subs, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revealed Comparative Advantage\n",
    "\n",
    "\"We next use the research space to predict the future presence of an individual, organization, or country in a research field. To make these predictions we define five possible states for individuals, organizations, or countries in a research field. These states are: inactive, active, nascent, intermediate, and developed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca = dict()\n",
    "sum_f = dict()\n",
    "sum_s = dict()\n",
    "sum_sf = 0\n",
    "\n",
    "for sf in x:\n",
    "    if sf[0] in sum_f:\n",
    "        sum_f[sf[0]] += x[sf]\n",
    "    else:\n",
    "        sum_f[sf[0]] = x[sf]\n",
    "\n",
    "    if sf[1] in sum_s:   \n",
    "        sum_s[sf[1]] += x[sf]\n",
    "    else:\n",
    "        sum_s[sf[1]] = x[sf]\n",
    "    \n",
    "    sum_sf += x[sf]\n",
    "\n",
    "    \n",
    "for sf in x:\n",
    "    rca[sf] = (x[sf]/sum_f[sf[0]])/(sum_s[sf[1]]/sum_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos computar o RCA de instituições e de municípios/estados/regiões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots:\n",
    "    1. Áreas de maior atuação das principais instituições do país\n",
    "    2. Mapa dos municípios/estados coloridos pelo RCA de uma área específica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E áreas urbanas\n",
    "\n",
    "\"First, we infer the country in which each affiliation-city pair is located; second, for each country, we compute a geographic distance matrix (using Vicenty’s formula) connecting each pair of cities; and lastly we use hierarchical clustering to define the different urban areas with the additional constraint that the maximum distance within each cluster has to be less than 50 km.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
